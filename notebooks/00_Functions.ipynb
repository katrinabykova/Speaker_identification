{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install --editable .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# display_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T00:35:06.595945Z",
     "start_time": "2019-12-08T00:35:06.577147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/display_audio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/display_audio.py'\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "def play_audio(file):\n",
    "    audio, sr = librosa.load(file, sr=16000, offset=0)\n",
    "    return Audio(audio, rate=sr)\n",
    "\n",
    "\n",
    "def display_waveplot(file):\n",
    "    audio, sr = librosa.load(file, sr=16000, offset=0)\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.waveplot(audio, sr=sr)\n",
    "    return \n",
    "\n",
    "\n",
    "def display_spectrogram(file):\n",
    "    audio, sr = librosa.load(file, sr=16000, offset=0)\n",
    "    X = librosa.stft(audio, n_fft=512, hop_length=200)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    # Scale if needed\n",
    "    Xdb = sklearn.preprocessing.scale(Xdb, axis=1, copy=False) \n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    librosa.display.specshow(Xdb, x_axis='time', y_axis='log', hop_length=200)\n",
    "    plt.colorbar()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T22:52:11.346496Z",
     "start_time": "2019-12-08T22:52:11.333640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/process_files.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/process_files.py'\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "\n",
    "def files_for_modeling(path, speaker_num):\n",
    "    '''\n",
    "    Returns a list of files from a data folder for a specified number of speakers. \n",
    "    Collects files in order they are in the folder.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    files = []\n",
    "    id_folder_list = id_folder_list[:speaker_num]\n",
    "    \n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        for file in file_path:      \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "           \n",
    "    return files\n",
    "\n",
    "\n",
    "def files_for_modeling_10_audios(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Spaecify the number of speakers. 10 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[speaker_start:speaker_stop]\n",
    "    speaker_count = 0\n",
    "    for id_folder in id_folder_list:\n",
    "        speaker_count+=1\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==10:\n",
    "                print('Done with speaker {}, have {} audio files'.format(speaker_count, count))\n",
    "                break\n",
    "    return files\n",
    "\n",
    "def files_for_modeling_10_audios_9_sec(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Spaecify the number of speakers. 10 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[speaker_start:speaker_stop]\n",
    "    speaker_count = 0\n",
    "    for id_folder in id_folder_list:\n",
    "        speaker_count+=1\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 170000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==10:\n",
    "                print('Done with speaker {}, have {} audio files'.format(speaker_count, count))\n",
    "                break\n",
    "    return files\n",
    "\n",
    "def files_for_modeling_3_audios(path, speaker_num):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Specify the number of speakers. 3 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[:speaker_num]\n",
    "    \n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==3:\n",
    "                break\n",
    "    return files\n",
    "\n",
    "\n",
    "def files_for_modeling_3_audios_random(path, speaker_num):\n",
    "    '''\n",
    "    Randompy collects audio files that are ~5 sec long. \n",
    "    Parameters: number of speakers, data path. \n",
    "    Returns 3 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "  # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "  # speaker_num = len(id_folder_list)\n",
    "    id_folder_list = random.choices(id_folder_list, k=speaker_num)\n",
    "\n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==3:\n",
    "                break\n",
    "    return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-09T23:46:46.414844Z",
     "start_time": "2019-12-09T23:46:46.400740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/process_audio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/process_audio.py'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import sklearn\n",
    "from itertools import combinations\n",
    "import random\n",
    "from src.data.process_files import files_for_modeling_10_audios\n",
    "\n",
    "\n",
    "def load_audio_file(file, sample_rate=16000, offset=0.4, duration=3):\n",
    "    \n",
    "    audio, sample_rate = librosa.load(file, sr=sample_rate, offset=offset, duration=duration)\n",
    "    \n",
    "    return audio, sample_rate\n",
    "\n",
    "def load_audio_file_9_sec(file, sample_rate=16000, offset=0.4, duration=9):\n",
    "    \n",
    "    audio, sample_rate = librosa.load(file, sr=sample_rate, offset=offset, duration=duration)\n",
    "    \n",
    "    return audio, sample_rate\n",
    "\n",
    "\n",
    "def fourier_transform(x):\n",
    "    X = librosa.stft(x, n_fft=512, hop_length=200)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    return Xdb\n",
    "\n",
    "\n",
    "def rescale(Xdb):    \n",
    "    Xdb_rescaled = sklearn.preprocessing.scale(Xdb, axis=1, copy=False) # Scale\n",
    "    return Xdb_rescaled\n",
    "\n",
    "\n",
    "def resize(Xdb_rescaled):    \n",
    "    Xdb_resized = np.resize(Xdb_rescaled, (224, 224))\n",
    "    return Xdb_resized\n",
    "\n",
    "def resize_9_sec(Xdb_rescaled):    \n",
    "    Xdb_resized = np.resize(Xdb_rescaled, (224, 672))\n",
    "    return Xdb_resized\n",
    "\n",
    "\n",
    "def VGG16_resize_9_sec(Xdb_resized):  \n",
    "    '''\n",
    "    Reshapes features to VGG16 input format. Specifically, adds channel dimensions.\n",
    "    '''\n",
    "    Xdb_3D = np.stack((Xdb_resized[:,:224], \n",
    "                       Xdb_resized[:,224:448], \n",
    "                       Xdb_resized[:,448:]),axis = 2)\n",
    "    return Xdb_3D\n",
    "\n",
    "def VGG16_resize(Xdb_resized):  \n",
    "    '''\n",
    "    Reshapes features to VGG16 input format. Specifically, adds channel dimensions.\n",
    "    '''\n",
    "    Xdb_3D = np.stack((Xdb_resized, \n",
    "                       Xdb_resized, \n",
    "                       Xdb_resized),axis = 2)\n",
    "    return Xdb_3D\n",
    "\n",
    "\n",
    "def speaker_id(file):\n",
    "    '''\n",
    "    Returns speaker ID for a given audio file.\n",
    "    '''\n",
    "    path_split_1 = os.path.split(file)\n",
    "    path_split_2 = os.path.split(path_split_1[0])\n",
    "    path_split_3 = os.path.split(path_split_2[0])  \n",
    "    y = int(path_split_3[1])\n",
    "    return y\n",
    "\n",
    "def file_name(file):\n",
    "    '''\n",
    "    Returns file name.\n",
    "    '''\n",
    "    name_file = os.path.split(file)[1]\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def one_observation_VGG16(file):\n",
    "    audio, _ = load_audio_file(file)\n",
    "    Xdb = fourier_transform(audio)\n",
    "    Xdb_rescaled = rescale(Xdb)\n",
    "    Xdb_resized = resize(Xdb_rescaled)\n",
    "    Xdb_3D = VGG16_resize(Xdb_resized)\n",
    "   \n",
    "    try:\n",
    "        y = speaker_id(file)\n",
    "        name_file = file_name(file)\n",
    "    except ValueError:\n",
    "        y = 'None'\n",
    "        name_file = 'None'\n",
    "    return Xdb_3D, y, name_file\n",
    "\n",
    "def one_observation_9_sec(file):\n",
    "    audio, _ = load_audio_file_9_sec(file)\n",
    "    Xdb = fourier_transform(audio)\n",
    "    Xdb_rescaled = rescale(Xdb)\n",
    "    Xdb_resized = resize_9_sec(Xdb_rescaled)\n",
    "    Xdb_3D = VGG16_resize_9_sec(Xdb_resized)\n",
    "   \n",
    "    try:\n",
    "        y = speaker_id(file)\n",
    "        name_file = file_name(file)\n",
    "    except ValueError:\n",
    "        y = 'None'\n",
    "        name_file = 'None'\n",
    "    return Xdb_3D, y, name_file\n",
    "\n",
    "\n",
    "def one_observation_spec(file):\n",
    "    audio, _ = load_audio_file(file)\n",
    "    Xdb = fourier_transform(audio)\n",
    "    Xdb_resized = resize(Xdb)\n",
    "    try:\n",
    "        y = speaker_id(file)\n",
    "        name_file = file_name(file)\n",
    "    except ValueError:\n",
    "        y = 'None'\n",
    "        name_file = 'None'\n",
    "    \n",
    "    return Xdb_resized, y, name_file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio_to_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-08T23:11:00.045777Z",
     "start_time": "2019-12-08T23:11:00.032260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/audio_to_features.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/audio_to_features.py'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "from src.data import process_files\n",
    "from src.data import process_audio\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "\n",
    "def file_to_features(path, speaker_start, speaker_stop, one_observation_func):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and reshapes them for a siamese net.\n",
    "    '''\n",
    "    \n",
    "    files = process_files.files_for_modeling_10_audios(path, speaker_start, speaker_stop)\n",
    "    \n",
    "    # Extract features\n",
    "    data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "    file_name_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id, name_file = process_audio.one_observation_func(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "        file_name_list.append(name_file)\n",
    "        \n",
    "    data['speaker_id'] = id_list\n",
    "    data['features'] = Xdb_3D_list  \n",
    "    data['file_name'] = file_name_list \n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def VGG16_features(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and generates embeddings with VGG16.\n",
    "    '''\n",
    "    files = process_files.files_for_modeling_10_audios(path, speaker_start, speaker_stop)\n",
    "    \n",
    "    # Extract features\n",
    "    data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "    file_name_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id, name_file = process_audio.one_observation_VGG16(file) # Features and label for one obervation = audio file\n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "        file_name_list.append(name_file)\n",
    "        \n",
    "    data['speaker_id'] = id_list\n",
    "    data['features'] = Xdb_3D_list  \n",
    "    data['file_name'] = file_name_list \n",
    "    \n",
    "    # Reshape features and target for modeling with VGG16 base model or alike\n",
    "    X = np.array(data.features.tolist())\n",
    "    \n",
    "    # Load CNN base model - VGG16\n",
    "    VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3)) # remove top dense layers\n",
    " \n",
    "    for layer in VGG16_model.layers:     # freeze convolutional layers \n",
    "        layer.trainable = False  \n",
    "    \n",
    "    embeddings = VGG16_model.predict(X)\n",
    "    emb_lst = [i for i in embeddings]\n",
    "    data['VGG16_embds'] = emb_lst\n",
    "    \n",
    "    return data\n",
    "\n",
    "def VGG16_features_9_sec(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and generates embeddings with VGG16.\n",
    "    '''\n",
    "    files = process_files.files_for_modeling_10_audios_9_sec(path, speaker_start, speaker_stop)\n",
    "    \n",
    "    # Extract features\n",
    "    data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "    file_name_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id, name_file = process_audio.one_observation_9_sec(file) # Features and label for one obervation = audio file\n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "        file_name_list.append(name_file)\n",
    "        \n",
    "    data['speaker_id'] = id_list\n",
    "    data['features'] = Xdb_3D_list  \n",
    "    data['file_name'] = file_name_list \n",
    "    \n",
    "    # Reshape features and target for modeling with VGG16 base model or alike\n",
    "    X = np.array(data.features.tolist())\n",
    "    \n",
    "    # Load CNN base model - VGG16\n",
    "    VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3)) # remove top dense layers\n",
    " \n",
    "    for layer in VGG16_model.layers:     # freeze convolutional layers \n",
    "        layer.trainable = False  \n",
    "    \n",
    "    embeddings = VGG16_model.predict(X)\n",
    "    emb_lst = [i for i in embeddings]\n",
    "    data['VGG16_embds'] = emb_lst\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "# Move out when get the src import to work\n",
    "\n",
    "def files_for_modeling_10_audios(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Spaecify the number of speakers. 10 files per speaker.\n",
    "    '''\n",
    "    \n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[speaker_start:speaker_stop]\n",
    "    speaker_count = 0\n",
    "    for id_folder in id_folder_list:\n",
    "        speaker_count+=1\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==10:\n",
    "                print('Done with speaker {}, have {} audio files'.format(speaker_count, count))\n",
    "                break\n",
    "    return files\n",
    "\n",
    "\n",
    "def file_to_VGG16_features(file):\n",
    "    '''\n",
    "    Extracts VGG16 embeddings from an audio file.\n",
    "    '''\n",
    "    # Extract audio features (spectrogram)\n",
    "    Xdb_3D, speaker_id, name_file = process_audio.one_observation_VGG16(file)\n",
    "    \n",
    "    # Reshape features and target for modeling with VGG16 base model or alike\n",
    "    X = np.reshape(Xdb_3D, (1, 224, 224, 3))\n",
    "    \n",
    "    # Load CNN base model - VGG16\n",
    "    VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3)) # remove top dense layers\n",
    " \n",
    "    for layer in VGG16_model.layers:     # freeze convolutional layers \n",
    "        layer.trainable = False  \n",
    "    \n",
    "    embeddings = VGG16_model.predict(X)\n",
    "    embeddings = np.reshape(embeddings, (7, 7, 512))\n",
    "    \n",
    "    return embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# features_for_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T19:19:29.870031Z",
     "start_time": "2019-12-04T19:19:29.855681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/features_for_model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/features_for_model.py'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import sklearn\n",
    "from itertools import permutations, combinations \n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def siamese_VGG16_features(data):\n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in combinations(data.VGG16_embds, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in combinations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in combinations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] # 1 never happens \n",
    "    \n",
    "    # X and y\n",
    "    siam_data_X = siam_data_filtered[['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id']].copy()\n",
    "    \n",
    "    siam_y = siam_data_filtered.siam_targets\n",
    "    \n",
    "    # Undersample target 0 (different speakers)\n",
    "    rus = RandomUnderSampler(random_state=4)\n",
    "    X_res, y_res = rus.fit_resample(siam_data_X, siam_y)\n",
    "    \n",
    "    X_res_data = pd.DataFrame(X_res, columns=['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id'])\n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(X_res_data.siam_features.tolist())\n",
    "    y = np.array(y_res.tolist())\n",
    "\n",
    "    return X, y, siam_data, X_res_data\n",
    "\n",
    "\n",
    "def siamese_spec_features(data):\n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in combinations(data.features, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in combinations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in combinations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] # 1 never happens \n",
    "    \n",
    "    # X and y\n",
    "    siam_data_X = siam_data_filtered[['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id']].copy()\n",
    "    \n",
    "    siam_y = siam_data_filtered.siam_targets\n",
    "    \n",
    "    # Undersample target 0 (different speakers)\n",
    "    rus = RandomUnderSampler(random_state=4)\n",
    "    X_res, y_res = rus.fit_resample(siam_data_X, siam_y)\n",
    "    \n",
    "    X_res_data = pd.DataFrame(X_res, columns=['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id'])\n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(X_res_data.siam_features.tolist())\n",
    "    y = np.array(y_res.tolist())\n",
    "\n",
    "    return X, y, siam_data, X_res_data\n",
    "\n",
    "\n",
    "def siamese_VGG16_features_unbal(data):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and reshapes them for a siamese net.\n",
    "    '''\n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in permutations(data.features, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in permutations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in permutations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] #1 never happens \n",
    "    \n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(siam_data_filtered.siam_features.tolist())\n",
    "    y = np.array(siam_data_filtered.siam_targets.tolist())\n",
    "    \n",
    "    return X, y, siam_data, siam_data_filtered\n",
    "\n",
    "\n",
    "def reshape_for_cnn(X_res_data, y_res):\n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(X_res_data.siam_features.tolist())\n",
    "    y = np.array(y_res.tolist())\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one_shot_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-04T00:07:19.683612Z",
     "start_time": "2019-12-04T00:07:19.672305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/models/one_shot_learning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/models/one_shot_learning.py'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data import process_audio\n",
    "import random\n",
    "\n",
    "def get_samples_random(path, speaker_num):\n",
    "    '''\n",
    "    Extracts features and targets from audio files.\n",
    "    '''\n",
    "    files = process_audio.files_for_modeling_3_audios_random(path, speaker_num)\n",
    "    \n",
    "    # Extract features\n",
    "    speaker_data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id = process_audio.one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "    \n",
    "    speaker_data['speaker_id'] = id_list\n",
    "    speaker_data['features'] = Xdb_3D_list  \n",
    "    \n",
    "    return speaker_data\n",
    "\n",
    "def get_samples_in_order(path, speaker_num):\n",
    "    '''\n",
    "    Extracts features and targets from audio files.\n",
    "    '''\n",
    "    files = process_audio.files_for_modeling_3_audios(path, speaker_num)\n",
    "    \n",
    "    # Extract features\n",
    "    speaker_data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id = process_audio.one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "    \n",
    "    speaker_data['speaker_id'] = id_list\n",
    "    speaker_data['features'] = Xdb_3D_list  \n",
    "    \n",
    "    return speaker_data\n",
    "\n",
    "def one_shot_set_spec_features(speaker_data, n_way):\n",
    "    '''\n",
    "    Returns one shot learning sample set with n_way sample pairs.\n",
    "    '''\n",
    "    \n",
    "    # Randomly select n_way samples \n",
    "    ids = []\n",
    "    samples = []\n",
    "\n",
    "    while len(ids)<n_way:\n",
    "        sample = speaker_data.sample(1, replace=False)\n",
    "        if sample.iloc[0]['speaker_id'] not in ids:\n",
    "            ids.append(sample.iloc[0]['speaker_id'])\n",
    "            samples.append(sample.iloc[0]['features'])\n",
    "#             print(ids)\n",
    "            \n",
    "    # Select a sample from the same speaker for the first sample \n",
    "    test_sample_df = speaker_data.loc[speaker_data.speaker_id==ids[0]]\n",
    "    if test_sample_df.shape[0]==1:  # only one audio is avalable for this speaker\n",
    "        test_sample = test_sample_df.iloc[0]['features'] \n",
    "#         print('only one')\n",
    "    else:\n",
    "        test_sample = 'empty'\n",
    "        while test_sample=='empty':\n",
    "            audio = test_sample_df.sample(1)\n",
    "            if not np.array_equal(audio.iloc[0]['features'], samples[0]):\n",
    "                test_sample = audio.iloc[0]['features'] \n",
    "        \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    # Targets\n",
    "    targets = np.zeros((n_way,))\n",
    "    targets[0] = 1\n",
    "    \n",
    "    return pairs, targets\n",
    "\n",
    "def one_shot_set_VGG16_features(speaker_data, n_way):\n",
    "    '''\n",
    "    Returns one shot learning sample set with n_way sample pairs.\n",
    "    '''\n",
    "    \n",
    "    # Randomly select n_way samples \n",
    "    ids = []\n",
    "    samples = []\n",
    "\n",
    "    while len(ids)<n_way:\n",
    "        sample = speaker_data.sample(1, replace=False)\n",
    "        if sample.iloc[0]['speaker_id'] not in ids:\n",
    "            ids.append(sample.iloc[0]['speaker_id'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "#             print(ids)\n",
    "            \n",
    "    # Select a sample from the same speaker for the first sample \n",
    "    test_sample_df = speaker_data.loc[speaker_data.speaker_id==ids[0]]\n",
    "    if test_sample_df.shape[0]==1:  # only one audio is avalable for this speaker\n",
    "        test_sample = test_sample_df.iloc[0]['VGG16_embds'] \n",
    "#         print('only one')\n",
    "    else:\n",
    "        test_sample = 'empty'\n",
    "        while test_sample=='empty':\n",
    "            audio = test_sample_df.sample(1)\n",
    "            if not np.array_equal(audio.iloc[0]['VGG16_embds'], samples[0]):\n",
    "                test_sample = audio.iloc[0]['VGG16_embds'] \n",
    "        \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    # Targets\n",
    "    targets = np.zeros((n_way,))\n",
    "    targets[0] = 1\n",
    "    \n",
    "    return pairs, targets\n",
    "\n",
    "\n",
    "def one_shot_score_VGG16_features(model, trials, speaker_data, n_way):\n",
    "    '''\n",
    "    Returns percent of correctly predicted one shot trials.\n",
    "    '''\n",
    "    n_correct = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        pairs, targets = one_shot_set_VGG16_features(speaker_data, n_way)\n",
    "        probs = model.predict([pairs[:, 0], pairs[:, 1]])\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "        count+=1\n",
    "        current_score = 100.0 * n_correct / count\n",
    "        print('Trial {}, current score {}'.format(count, current_score), end='\\r')\n",
    "    percent_correct = 100.0 * n_correct / trials\n",
    "    \n",
    "    return percent_correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-10T02:30:29.494435Z",
     "start_time": "2019-12-10T02:30:29.483225Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/models/applications.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/models/applications.py'\n",
    "\n",
    "import numpy as np\n",
    "from src.models import one_shot_learning\n",
    "from src.data import audio_to_features\n",
    "\n",
    "def sample_set_same_speaker(speaker_data):\n",
    "    '''\n",
    "    Returns 5 pairs of audio files for the same speaker. Same audio file paired with 5 distinct audios.\n",
    "    '''\n",
    "    # Randomly select a speaker\n",
    "    speaker_id = int(speaker_data.speaker_id.sample(1, replace=False))\n",
    "    same_speaker = speaker_data.loc[speaker_data.speaker_id==speaker_id]\n",
    "    \n",
    "    files = []\n",
    "    samples = []\n",
    "\n",
    "    while len(samples)<6:\n",
    "        sample = same_speaker.sample(1, replace=False)\n",
    "        if sample.iloc[0]['file_name'] not in files:\n",
    "            files.append(sample.iloc[0]['file_name'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "            \n",
    "    # Assign a test semple\n",
    "    test_sample = samples[0]\n",
    "    test_file = files[0]\n",
    "    samples = samples[1:]\n",
    "    \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "    \n",
    "    files_pairs = [(test_file, files) for sample in samples]\n",
    "    files_pairs = np.array(files_pairs)\n",
    "    \n",
    "    return pairs, files_pairs\n",
    "\n",
    "\n",
    "def sample_set_different_speaker(speaker_data):\n",
    "    '''\n",
    "    Returns 5 pairs of audio files for the same speaker. Same audio file paired with 5 distinct audios.\n",
    "    '''\n",
    "    # Randomly select a speaker\n",
    "    speaker_id = int(speaker_data.speaker_id.sample(1, replace=False))\n",
    "    same_speaker = speaker_data.loc[speaker_data.speaker_id==speaker_id]\n",
    "    \n",
    "    files = []\n",
    "    samples = []\n",
    "\n",
    "    while len(samples)<5:\n",
    "        sample = same_speaker.sample(1, replace=False) # Randomly pick a row\n",
    "        if sample.iloc[0]['file_name'] not in files:\n",
    "            files.append(sample.iloc[0]['file_name'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "            \n",
    "    # Select a test semple\n",
    "    test_sample = 'empty'\n",
    "    while test_sample=='empty':\n",
    "        test = speaker_data.sample(1, replace=False) # Randomly pick a row\n",
    "        if test.iloc[0]['speaker_id'] != speaker_id:\n",
    "            test_sample = test.iloc[0]['VGG16_embds']\n",
    "    \n",
    "    test_file = test.iloc[0]['file_name']\n",
    "    \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "    \n",
    "    files_pairs = [(test_file, files) for sample in samples]\n",
    "    files_pairs = np.array(files_pairs)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def one_speaker_authentification_1(model, trials, speaker_data, n):\n",
    "    '''\n",
    "    Returns percent of correctly predicted speaker authentifications.\n",
    "    '''\n",
    "    probs_list = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "        pairs, files = sample_set_same_speaker_n(speaker_data, n)\n",
    "        probs = model.predict([pairs[:, 0], pairs[:, 1]])\n",
    "#         probs_list.append(probs)\n",
    "    return probs, files\n",
    "\n",
    "def one_speaker_authentification_0(model, trials, speaker_data, n):\n",
    "    '''\n",
    "    Returns percent of correctly predicted speaker authentifications.\n",
    "    '''\n",
    "    probs_list = []\n",
    "    \n",
    "    for i in range(trials):\n",
    "        pairs = sample_set_different_speaker_n(speaker_data, n)\n",
    "        probs = model.predict([pairs[:, 0], pairs[:, 1]])\n",
    "#         probs_list.append(probs)\n",
    "    return probs\n",
    "\n",
    "\n",
    "def recorded_sample_set(test_file, file_list):\n",
    "    '''\n",
    "    Returns 5 pairs of audio files made from voiceprint and a test sample.\n",
    "    Voiceprint is a set of 5 audios from the saved speaker.\n",
    "    '''\n",
    "    # Voiceprint VGG16 embeddings:\n",
    "    samples = []\n",
    "    for file in file_list:\n",
    "            embeddings = audio_to_features.file_to_VGG16_features(file)\n",
    "            samples.append(embeddings)\n",
    "            \n",
    "    # Test sample VGG16 embeddings\n",
    "    sample = audio_to_features.file_to_VGG16_features(test_file)\n",
    "    \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "\n",
    "def sample_set_same_speaker_n(speaker_data, n):\n",
    "    '''\n",
    "    Returns n pairs of audio files for the same speaker. Same audio file paired with n distinct audios.\n",
    "    '''\n",
    "    # Randomly select a speaker\n",
    "    speaker_id = int(speaker_data.speaker_id.sample(1, replace=False))\n",
    "    same_speaker = speaker_data.loc[speaker_data.speaker_id==speaker_id]\n",
    "    \n",
    "    files = []\n",
    "    samples = []\n",
    "\n",
    "    while len(samples)<n+1:\n",
    "        sample = same_speaker.sample(1, replace=False)\n",
    "        if sample.iloc[0]['file_name'] not in files:\n",
    "            files.append(sample.iloc[0]['file_name'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "            \n",
    "    # Assign a test semple\n",
    "    test_sample = samples[0]\n",
    "    test_file = files[0]\n",
    "    samples = samples[1:]\n",
    "    \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "    \n",
    "    files_pairs = [(test_file, files) for sample in samples]\n",
    "    files_pairs = np.array(files_pairs)\n",
    "    \n",
    "    return pairs, files\n",
    "\n",
    "\n",
    "def sample_set_different_speaker_n(speaker_data, n):\n",
    "    '''\n",
    "    Returns 5 pairs of audio files for the same speaker. Same audio file paired with 5 distinct audios.\n",
    "    '''\n",
    "    # Randomly select a speaker\n",
    "    speaker_id = int(speaker_data.speaker_id.sample(1, replace=False))\n",
    "    same_speaker = speaker_data.loc[speaker_data.speaker_id==speaker_id]\n",
    "    \n",
    "    files = []\n",
    "    samples = []\n",
    "\n",
    "    while len(samples)<n:\n",
    "        sample = same_speaker.sample(1, replace=False) # Randomly pick a row\n",
    "        if sample.iloc[0]['file_name'] not in files:\n",
    "            files.append(sample.iloc[0]['file_name'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "            \n",
    "    # Select a test semple\n",
    "    test_sample = 'empty'\n",
    "    while test_sample=='empty':\n",
    "        test = speaker_data.sample(1, replace=False) # Randomly pick a row\n",
    "        if test.iloc[0]['speaker_id'] != speaker_id:\n",
    "            test_sample = test.iloc[0]['VGG16_embds']\n",
    "    \n",
    "    test_file = test.iloc[0]['file_name']\n",
    "    \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "    \n",
    "    files_pairs = [(test_file, files) for sample in samples]\n",
    "    files_pairs = np.array(files_pairs)\n",
    "    \n",
    "    return pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process_audio_siam - remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T03:03:11.859490Z",
     "start_time": "2019-12-03T03:03:11.848641Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/process_audio_siam.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/process_audio_siam.py'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import sklearn\n",
    "from itertools import permutations, combinations\n",
    "import random\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "def files_for_modeling_10_audios(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Spaecify the number of speakers. 3 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[speaker_start:speaker_stop]\n",
    "    speaker_count = 0\n",
    "    for id_folder in id_folder_list:\n",
    "        speaker_count+=1\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==10:\n",
    "                print('Done with speaker {}, have {} audio files'.format(speaker_count, count))\n",
    "                break\n",
    "    return files\n",
    "\n",
    "\n",
    "def files_for_modeling_3_audios(path, speaker_num):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. Spaecify the number of speakers. 3 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[:speaker_num]\n",
    "    \n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==3:\n",
    "                break\n",
    "    return files\n",
    "\n",
    "\n",
    "def files_for_modeling_3_audios_random(path, speaker_num):\n",
    "    '''\n",
    "    Collects audio files that are ~5 sec long. \n",
    "    Parameters: number of speakers, data path. \n",
    "    Returns 3 files per speaker.\n",
    "    '''\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "  # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "  # speaker_num = len(id_folder_list)\n",
    "    id_folder_list = random.choices(id_folder_list, k=speaker_num)\n",
    "\n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        count = 0\n",
    "        for file in file_path: \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "                count+=1\n",
    "            if count==3:\n",
    "                break\n",
    "    return files\n",
    "\n",
    "\n",
    "def files_for_modeling(path, speaker_num):\n",
    "    id_folder_list =  glob.glob(os.path.join(path, '*'))\n",
    "    # folders_ids =  glob.glob(os.path.join(data_dir, '*'))\n",
    "    files = []\n",
    "#     speaker_num = len(id_folder_list)\n",
    "    id_folder_list = id_folder_list[:speaker_num]\n",
    "    \n",
    "    for id_folder in id_folder_list:\n",
    "        file_path  = glob.glob(os.path.join(id_folder, '*', '*.flac'))\n",
    "        for file in file_path:      \n",
    "            if os.stat(file).st_size > 75000:\n",
    "                files.append(file)\n",
    "           \n",
    "    return files\n",
    "\n",
    "\n",
    "def load_audio_file(file, sample_rate=16000, offset=0.4, duration=3):\n",
    "    \n",
    "    audio, sample_rate = librosa.load(file, sr=sample_rate, offset=offset, duration=duration)\n",
    "    \n",
    "    return audio, sample_rate\n",
    "\n",
    "def fourier_transform(x):\n",
    "    X = librosa.stft(x, n_fft=512, hop_length=200)\n",
    "    Xdb = librosa.amplitude_to_db(abs(X))\n",
    "    return Xdb\n",
    "\n",
    "\n",
    "def pre_processing(Xdb):    \n",
    "    Xdb = sklearn.preprocessing.scale(Xdb, axis=1, copy=False) # Scale\n",
    "    Xdb_resized = np.resize(Xdb, (224, 224))\n",
    "    Xdb_3D = np.stack((Xdb_resized, Xdb_resized, Xdb_resized),axis = 2)\n",
    "    return Xdb_3D\n",
    "\n",
    "\n",
    "def speaker_id(file):\n",
    "    path_split_1 = os.path.split(file)\n",
    "    path_split_2 = os.path.split(path_split_1[0])\n",
    "    path_split_3 = os.path.split(path_split_2[0])  \n",
    "    y = int(path_split_3[1])\n",
    "    return y\n",
    "\n",
    "def file_name(file):\n",
    "    name_file = os.path.split(file)[1]\n",
    "    return name_file\n",
    "\n",
    "\n",
    "def one_observation(file):\n",
    "    audio, _ = load_audio_file(file)\n",
    "    Xdb = fourier_transform(audio)\n",
    "    Xdb_3D = pre_processing(Xdb)\n",
    "    y = speaker_id(file)\n",
    "    name_file = file_name(file)\n",
    "    return Xdb_3D, y, name_file\n",
    "\n",
    "\n",
    "def audio_to_features(path, speaker_num):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and reshapes them for a siamese net.\n",
    "    '''\n",
    "    files = files_for_modeling_3_audios(path, speaker_num)\n",
    "    \n",
    "    # Extract features\n",
    "    data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "    file_name_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id, name_file = one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "        file_name_list.append(name_file)\n",
    "        \n",
    "    data['speaker_id'] = id_list\n",
    "    data['features'] = Xdb_3D_list  \n",
    "    data['file_name'] = file_name_list \n",
    "    \n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in permutations(data.features, 2)]\n",
    "    siam_targets_tup = [comb for comb in permutations(data.speaker_id, 2)]\n",
    "    siam_files_tup = [comb for comb in permutations(data.file_name, 2)]\n",
    "    \n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    \n",
    "    # Remove pairs made up the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0]\n",
    "    \n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(siam_data_filtered.siam_features.tolist())\n",
    "    y = np.array(siam_data_filtered.siam_targets.tolist())\n",
    "    \n",
    "    return X, y, siam_data, siam_data_filtered\n",
    "\n",
    "\n",
    "def ten_audio_to_features(path, speaker_start, speaker_stop):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and reshapes them for a siamese net.\n",
    "    '''\n",
    "    files = files_for_modeling_10_audios(path, speaker_start, speaker_stop)\n",
    "    \n",
    "    # Extract features\n",
    "    data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "    file_name_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id, name_file = one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "        file_name_list.append(name_file)\n",
    "        \n",
    "    data['speaker_id'] = id_list\n",
    "    data['features'] = Xdb_3D_list  \n",
    "    data['file_name'] = file_name_list \n",
    "    \n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in permutations(data.features, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in permutations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in permutations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] #1 never happens \n",
    "    \n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(siam_data_filtered.siam_features.tolist())\n",
    "    y = np.array(siam_data_filtered.siam_targets.tolist())\n",
    "    \n",
    "    return X, y, siam_data, siam_data_filtered\n",
    "\n",
    "\n",
    "def audio_data_to_siam_features(data):\n",
    "    '''\n",
    "    Extracts features and targets from audio files and reshapes them for a siamese net.\n",
    "    '''\n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in permutations(data.features, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in permutations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in permutations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] #1 never happens \n",
    "    \n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(siam_data_filtered.siam_features.tolist())\n",
    "    y = np.array(siam_data_filtered.siam_targets.tolist())\n",
    "    \n",
    "    return X, y, siam_data, siam_data_filtered\n",
    "\n",
    "\n",
    "def dataframe_to_siamese_features_LSTM(data):\n",
    "    # Process features for siamese model\n",
    "    siam_features = [comb for comb in combinations(data.features, 2)]\n",
    "#     print(len(siam_features))\n",
    "    siam_targets_tup = [comb for comb in combinations(data.speaker_id, 2)]\n",
    "#     print(siam_targets_tup)\n",
    "    siam_files_tup = [comb for comb in combinations(data.file_name, 2)]\n",
    "#     print(siam_files_tup)\n",
    "    siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    siam_same_file = [1 if a==b else 0 for a, b in siam_files_tup]\n",
    "    siam_same_id = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "    \n",
    "    siam_data = pd.DataFrame()\n",
    "    siam_data['siam_targets'] = siam_targets\n",
    "    siam_data['siam_features'] = siam_features  \n",
    "    siam_data['siam_pairs_ids'] = siam_targets_tup \n",
    "    siam_data['file_names'] = siam_files_tup \n",
    "    siam_data['siam_same_file'] = siam_same_file \n",
    "    siam_data['siam_same_id'] = siam_same_id \n",
    "    \n",
    "    # Remove pairs made up by the same file\n",
    "    siam_data_filtered = siam_data.loc[siam_data.siam_same_file==0] # 1 never happens \n",
    "    \n",
    "    # X and y\n",
    "    siam_data_X = siam_data_filtered[['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id']].copy()\n",
    "    \n",
    "    siam_y = siam_data_filtered.siam_targets\n",
    "    \n",
    "    # Undersample target 0 (different speakers)\n",
    "    rus = RandomUnderSampler(random_state=4)\n",
    "    X_res, y_res = rus.fit_resample(siam_data_X, siam_y)\n",
    "    \n",
    "    X_res_data = pd.DataFrame(X_res, columns=['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id'])\n",
    "    \n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(X_res_data.siam_features.tolist())\n",
    "    y = np.array(y_res.tolist())\n",
    "\n",
    "    return X, y, siam_data, X_res_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# balance_data - remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T02:37:58.547696Z",
     "start_time": "2019-12-03T02:37:58.536545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/balance_data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/balance_data.py'\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "\n",
    "def under_sample(siam_data_filtered):\n",
    "    '''\n",
    "    Undersamples the majority class (0, different speakers). Shuffles the dataframe befor the undersampling.\n",
    "    '''\n",
    "    # Shuffle data\n",
    "    siam_data_filtered = siam_data_filtered.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    # X and y\n",
    "    siam_data_X = siam_data_filtered[['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id']].copy()\n",
    "    \n",
    "    siam_y = siam_data_filtered.siam_targets\n",
    "    \n",
    "    # Undersample target 0 (different speakers)\n",
    "    rus = RandomUnderSampler(random_state=4)\n",
    "    X_res, y_res = rus.fit_resample(siam_data_X, siam_y)\n",
    "    \n",
    "    X_res_data = pd.DataFrame(X_res, columns=['siam_features', \n",
    "                                  'siam_pairs_ids', \n",
    "                                  'file_names', \n",
    "                                  'siam_same_file', \n",
    "                                  'siam_same_id'])\n",
    "\n",
    "    return X_res_data, y_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reshape_for_cnn - duplicated - moved to process audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-03T02:38:00.274095Z",
     "start_time": "2019-12-03T02:38:00.266458Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /Users/greenapple/project5/src/data/reshape.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/data/reshape.py'\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def reshape_for_cnn(X_res_data, y_res):\n",
    "    # Reshape features and target for modeling\n",
    "    X = np.array(X_res_data.siam_features.tolist())\n",
    "    y = np.array(y_res.tolist())\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# one_shot_learning_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T19:15:36.244973Z",
     "start_time": "2019-11-27T19:15:36.227227Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/greenapple/project5/src/models/one_shot_learning_VGG16.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/models/one_shot_learning_VGG16.py'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.data import process_audio\n",
    "import random\n",
    "\n",
    "def get_samples_random(path, speaker_num):\n",
    "    '''\n",
    "    Extracts features and targets from audio files.\n",
    "    '''\n",
    "    files = process_audio.files_for_modeling_3_audios_random(path, speaker_num)\n",
    "    \n",
    "    # Extract features\n",
    "    speaker_data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id = process_audio.one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "    \n",
    "    speaker_data['speaker_id'] = id_list\n",
    "    speaker_data['features'] = Xdb_3D_list  \n",
    "    \n",
    "    return speaker_data\n",
    "\n",
    "def get_samples_in_order(path, speaker_num):\n",
    "    '''\n",
    "    Extracts features and targets from audio files.\n",
    "    '''\n",
    "    files = process_audio.files_for_modeling_3_audios(path, speaker_num)\n",
    "    \n",
    "    # Extract features\n",
    "    speaker_data = pd.DataFrame()\n",
    "    Xdb_3D_list = []\n",
    "    id_list = []\n",
    "\n",
    "    for file in files:\n",
    "        Xdb_3D, speaker_id = process_audio.one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "        Xdb_3D_list.append(Xdb_3D)\n",
    "        id_list.append(speaker_id)\n",
    "    \n",
    "    speaker_data['speaker_id'] = id_list\n",
    "    speaker_data['features'] = Xdb_3D_list  \n",
    "    \n",
    "    return speaker_data\n",
    "\n",
    "def one_shot_set(speaker_data, n_way):\n",
    "    '''\n",
    "    Returns one shot learning sample set with n_way sample pairs.\n",
    "    '''\n",
    "    \n",
    "    # Randomly select n_way samples \n",
    "    ids = []\n",
    "    samples = []\n",
    "\n",
    "    while len(ids)<n_way:\n",
    "        sample = speaker_data.sample(1, replace=False)\n",
    "        if sample.iloc[0]['speaker_id'] not in ids:\n",
    "            ids.append(sample.iloc[0]['speaker_id'])\n",
    "            samples.append(sample.iloc[0]['VGG16_embds'])\n",
    "#             print(ids)\n",
    "            \n",
    "    # Select a sample from the same speaker for the first sample \n",
    "    test_sample_df = speaker_data.loc[speaker_data.speaker_id==ids[0]]\n",
    "    if test_sample_df.shape[0]==1:  # only one audio is avalable for this speaker\n",
    "        test_sample = test_sample_df.iloc[0]['VGG16_embds'] \n",
    "#         print('only one')\n",
    "    else:\n",
    "        test_sample = 'empty'\n",
    "        while test_sample=='empty':\n",
    "            audio = test_sample_df.sample(1)\n",
    "            if not np.array_equal(audio.iloc[0]['VGG16_embds'], samples[0]):\n",
    "                test_sample = audio.iloc[0]['VGG16_embds'] \n",
    "        \n",
    "    # Make pairs\n",
    "    pairs = [(test_sample, sample) for sample in samples]\n",
    "    pairs = np.array(pairs)\n",
    "\n",
    "    # Targets\n",
    "    targets = np.zeros((n_way,))\n",
    "    targets[0] = 1\n",
    "    \n",
    "    return pairs, targets\n",
    "\n",
    "\n",
    "def one_shot_score(model, trials, speaker_data, n_way):\n",
    "    '''\n",
    "    Returns percent of correctly predicted one shot trials.\n",
    "    '''\n",
    "    n_correct = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in range(trials):\n",
    "        pairs, targets = one_shot_set(speaker_data, n_way)\n",
    "        probs = model.predict([pairs[:, 0], pairs[:, 1]])\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct+=1\n",
    "        count+=1\n",
    "        current_score = 100.0 * n_correct / count\n",
    "        print('Trial {}, current score {}'.format(count, current_score), end='\\r')\n",
    "    percent_correct = 100.0 * n_correct / trials\n",
    "    \n",
    "    return percent_correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T00:32:21.874456Z",
     "start_time": "2019-11-28T00:32:21.860458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/greenapple/project5/src/models/history.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile '/Users/greenapple/project5/src/models/history.py'\n",
    "\n",
    "import json, codecs\n",
    "\n",
    "def save_hist(path, history):\n",
    "    with codecs.open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(history, f, separators=(',', ':'), sort_keys=True, indent=4) \n",
    "\n",
    "def load_hist(path):\n",
    "    n = {} # set history to empty\n",
    "    if os.path.exists(path): # reload history if it exists\n",
    "        with codecs.open(path, 'r', encoding='utf-8') as f:\n",
    "            n = json.loads(f.read())\n",
    "    return n\n",
    "\n",
    "def append_hist(h1, h2):\n",
    "    if h1 == {}:\n",
    "        return h2\n",
    "    else:\n",
    "        dest = {}\n",
    "        for key, value in h1.items():\n",
    "            dest[key] = value + h2[key]\n",
    "        return dest"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project4] *",
   "language": "python",
   "name": "conda-env-project4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "222px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
