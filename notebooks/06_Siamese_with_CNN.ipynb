{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:04:28.554867Z",
     "start_time": "2019-11-24T20:04:28.549875Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:04:33.712088Z",
     "start_time": "2019-11-24T20:04:29.034864Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import os\n",
    "import pickle\n",
    "from itertools import combinations\n",
    "import random\n",
    "\n",
    "from keras.models import Model, Input, Sequential, load_model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten, MaxPooling2D, ZeroPadding2D, Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "\n",
    "from src.data import process_audio\n",
    "from src.data import display_audio\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T20:04:35.148193Z",
     "start_time": "2019-11-24T20:04:35.053529Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese_CNN model with 10 speakers and 3 audio files per speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:15.878940Z",
     "start_time": "2019-11-24T22:41:15.706189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get audio files for 10 speakers\n",
    "path = '/Users/greenapple/project5/data/raw/LibriSpeech/dev-clean' # folder with training data\n",
    "files = process_audio.files_for_modeling_3_audios(path, 10)\n",
    "\n",
    "# Number of files for analysis\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:17.920875Z",
     "start_time": "2019-11-24T22:41:16.821925Z"
    }
   },
   "outputs": [],
   "source": [
    "# Extract features\n",
    "data = pd.DataFrame()\n",
    "Xdb_3D_list = []\n",
    "id_list = []\n",
    "\n",
    "for file in files:\n",
    "    Xdb_3D, speaker_id = process_audio.one_observation(file) # Features and label for one obervation = audio file\n",
    "    \n",
    "    Xdb_3D_list.append(Xdb_3D)\n",
    "    id_list.append(speaker_id)\n",
    "    \n",
    "data['speaker_id'] = id_list\n",
    "data['features'] = Xdb_3D_list  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:18.017665Z",
     "start_time": "2019-11-24T22:41:17.924040Z"
    }
   },
   "outputs": [],
   "source": [
    "# Process features for siamese model\n",
    "siam_features = [comb for comb in combinations(data.features, 2)]\n",
    "siam_targets_tup = [comb for comb in combinations(data.speaker_id, 2)]\n",
    "siam_targets = [1 if a==b else 0 for a, b in siam_targets_tup]\n",
    "# siam_indices = [comb for comb in combinations(list(range(data.shape[0])), 2)]\n",
    "\n",
    "siam_data = pd.DataFrame()\n",
    "siam_data['siam_targets'] = siam_targets\n",
    "siam_data['siam_features'] = siam_features  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:18.613130Z",
     "start_time": "2019-11-24T22:41:18.533483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 2)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siam_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:19.819273Z",
     "start_time": "2019-11-24T22:41:19.597471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reshape features and target for modeling\n",
    "X = np.array(siam_data.siam_features.tolist())\n",
    "y = np.array(siam_data.siam_targets.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:23.210242Z",
     "start_time": "2019-11-24T22:41:23.138001Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210,)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T22:41:34.334540Z",
     "start_time": "2019-11-24T22:41:34.259602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 2, 224, 224, 3)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T23:57:16.452604Z",
     "start_time": "2019-11-23T23:57:15.330020Z"
    }
   },
   "outputs": [],
   "source": [
    "# Siamese model 1\n",
    "\n",
    "# Build CNN branches\n",
    "CNN = Sequential(name='01_CNN')\n",
    "CNN.add(ZeroPadding2D((1,1),input_shape=(224,224,3)))\n",
    "CNN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "CNN.add(Dropout(0.2))\n",
    "\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "CNN.add(Dropout(0.2))\n",
    "\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "CNN.add(Dropout(0.2))\n",
    "\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "CNN.add(Dropout(0.2))\n",
    "\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(ZeroPadding2D((1,1)))\n",
    "CNN.add(Conv2D(512, (3, 3), activation='relu'))\n",
    "CNN.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "CNN.add(Dropout(0.2))\n",
    "\n",
    "CNN.add(Flatten())\n",
    "CNN.add(Dense(4096, activation='sigmoid'))\n",
    "\n",
    "# Define tensors for two input audios\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)    \n",
    "\n",
    "encoded_l = CNN(left_input)\n",
    "encoded_r = CNN(right_input)\n",
    "\n",
    "# Add a customized layer to compute the difference between the vectors/encodings\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "# Add a layer to classify the audios into \"same speaker\" = 1 or \"not the same\" = 0\n",
    "classification = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "# Siamese model\n",
    "siamese_model_1 = Model(inputs=[left_input,right_input],outputs=classification)\n",
    "\n",
    "# Adam optimizer\n",
    "siamese_model_1.compile(optimizer=Adam(lr = 0.00006),\n",
    "            loss=\"binary_crossentropy\", \n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T07:49:42.484186Z",
     "start_time": "2019-11-23T06:04:18.423620Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/greenapple/anaconda3/envs/project4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 168 samples, validate on 42 samples\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 734s 4s/step - loss: 0.6919 - acc: 0.6429 - val_loss: 0.6927 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 677s 4s/step - loss: 0.6758 - acc: 0.9226 - val_loss: 0.6926 - val_acc: 0.5714\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 671s 4s/step - loss: 0.4230 - acc: 0.9345 - val_loss: 0.6752 - val_acc: 0.7381\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 674s 4s/step - loss: 0.2566 - acc: 0.9345 - val_loss: 0.6655 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 611s 4s/step - loss: 0.2395 - acc: 0.9345 - val_loss: 0.6823 - val_acc: 0.6905\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 594s 4s/step - loss: 0.2546 - acc: 0.9345 - val_loss: 0.7002 - val_acc: 0.3333\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 596s 4s/step - loss: 0.2480 - acc: 0.9345 - val_loss: 0.6695 - val_acc: 0.8333\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 594s 4s/step - loss: 0.2498 - acc: 0.9345 - val_loss: 0.6700 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 581s 3s/step - loss: 0.2660 - acc: 0.9345 - val_loss: 0.6542 - val_acc: 0.8333\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 588s 4s/step - loss: 0.2622 - acc: 0.9345 - val_loss: 0.6270 - val_acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x129b351d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model_1.fit([X[:, 0], X[:, 1]], y, epochs=10, verbose=True, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T23:59:07.079592Z",
     "start_time": "2019-11-23T23:59:06.976225Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T23:57:19.821921Z",
     "start_time": "2019-11-23T23:57:19.697973Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"01_CNN\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_14 (ZeroPaddi (None, 226, 226, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 226, 226, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 114, 114, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 114, 114, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_18 (ZeroPaddi (None, 58, 58, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPaddi (None, 58, 58, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPaddi (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPaddi (None, 30, 30, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPaddi (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 117,479,232\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "CNN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T19:34:37.358196Z",
     "start_time": "2019-11-23T19:34:33.296450Z"
    }
   },
   "outputs": [],
   "source": [
    "siamese_model_1.save('/Users/greenapple/project5/models/siamese_model_1.h5') # save model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T01:14:10.668958Z",
     "start_time": "2019-11-24T01:14:06.856302Z"
    }
   },
   "outputs": [],
   "source": [
    "siamese_model_2.save('/Users/greenapple/project5/models/02_siamese_model.h5') # save model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T18:54:49.401028Z",
     "start_time": "2019-11-24T18:54:42.537715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training on 100 speakers 1 epoch\n",
    "siamese_model_2.save('/Users/greenapple/project5/models/02_2_siamese_model.h5') # save model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T01:14:13.835503Z",
     "start_time": "2019-11-24T01:14:10.671212Z"
    }
   },
   "outputs": [],
   "source": [
    "VGG16_like.save('/Users/greenapple/project5/models/VGG16_like.h5') # save model to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model_1.save_weights('/Users/greenapple/project5/models/01_siamese_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siamese_VGG16 model with 10 speakers and 3 audio files per speaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T00:22:35.947436Z",
     "start_time": "2019-11-24T00:22:32.922183Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load CNN branches - VGG16\n",
    "VGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224,224, 3)) # remove top dense layers\n",
    " \n",
    "for layer in VGG16_model.layers:     # freeze convolutional layers \n",
    "    layer.trainable = False    \n",
    "\n",
    "x = VGG16_model.output\n",
    "x = Flatten()(x) \n",
    "encodings = Dense(4096, activation='sigmoid')(x)\n",
    "\n",
    "# VGG16 with dense layers replaced\n",
    "VGG16_like = Model(inputs=VGG16_model.input, outputs=encodings, name='VGG16_like')\n",
    "VGG16_like.compile(optimizer=Adam(lr = 0.00006), loss='binary_crossentropy')\n",
    "\n",
    "# Define tensors for two input audios\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)    \n",
    "\n",
    "encoded_l = VGG16_like(left_input)\n",
    "encoded_r = VGG16_like(right_input)\n",
    "\n",
    "# Add a customized layer to compute the difference between the vectors/encodings\n",
    "L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
    "L1_distance = L1_layer([encoded_l, encoded_r])\n",
    "    \n",
    "# Add a layer to classify the audios into \"same speaker\" = 1 or \"not the same\" = 0\n",
    "classification = Dense(1,activation='sigmoid')(L1_distance)\n",
    "    \n",
    "# Siamese model\n",
    "siamese_model_2 = Model(inputs=[left_input,right_input],outputs=classification)\n",
    "\n",
    "# Adam optimizer\n",
    "siamese_model_2.compile(optimizer=Adam(lr = 0.00006),\n",
    "            loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T00:31:59.190234Z",
     "start_time": "2019-11-24T00:31:59.094017Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_12 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "01_CNN (Sequential)             (None, 4096)         117479232   input_12[0][0]                   \n",
      "                                                                 input_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 4096)         0           01_CNN[1][0]                     \n",
      "                                                                 01_CNN[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 1)            4097        lambda_4[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 117,483,329\n",
      "Trainable params: 117,483,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model_1.summary() # model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T00:25:35.708269Z",
     "start_time": "2019-11-24T00:25:35.439870Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG16_like\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 4096)              102764544 \n",
      "=================================================================\n",
      "Total params: 117,479,232\n",
      "Trainable params: 102,764,544\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_like.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T01:12:53.548832Z",
     "start_time": "2019-11-24T00:33:07.502962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 168 samples, validate on 42 samples\n",
      "Epoch 1/10\n",
      "168/168 [==============================] - 244s 1s/step - loss: 0.4272 - acc: 0.9345 - val_loss: 0.4850 - val_acc: 0.8333\n",
      "Epoch 2/10\n",
      "168/168 [==============================] - 245s 1s/step - loss: 0.2220 - acc: 0.9345 - val_loss: 0.5547 - val_acc: 0.8333\n",
      "Epoch 3/10\n",
      "168/168 [==============================] - 235s 1s/step - loss: 0.1893 - acc: 0.9345 - val_loss: 0.6035 - val_acc: 0.8333\n",
      "Epoch 4/10\n",
      "168/168 [==============================] - 233s 1s/step - loss: 0.1610 - acc: 0.9345 - val_loss: 0.6315 - val_acc: 0.8333\n",
      "Epoch 5/10\n",
      "168/168 [==============================] - 233s 1s/step - loss: 0.1334 - acc: 0.9345 - val_loss: 0.6298 - val_acc: 0.8333\n",
      "Epoch 6/10\n",
      "168/168 [==============================] - 231s 1s/step - loss: 0.1092 - acc: 0.9524 - val_loss: 0.6353 - val_acc: 0.8333\n",
      "Epoch 7/10\n",
      "168/168 [==============================] - 257s 2s/step - loss: 0.0893 - acc: 0.9702 - val_loss: 0.6535 - val_acc: 0.8333\n",
      "Epoch 8/10\n",
      "168/168 [==============================] - 234s 1s/step - loss: 0.0749 - acc: 0.9881 - val_loss: 0.6771 - val_acc: 0.8333\n",
      "Epoch 9/10\n",
      "168/168 [==============================] - 228s 1s/step - loss: 0.0617 - acc: 0.9940 - val_loss: 0.6959 - val_acc: 0.8333\n",
      "Epoch 10/10\n",
      "168/168 [==============================] - 245s 1s/step - loss: 0.0526 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b6f64438>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model with 10 speakers, 3 audios per speaker\n",
    "siamese_model_2.fit([X[:, 0], X[:, 1]], y, epochs=10, verbose=True, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T02:51:14.680450Z",
     "start_time": "2019-11-24T02:51:14.582158Z"
    }
   },
   "outputs": [],
   "source": [
    "import src.data.process_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T05:01:00.298030Z",
     "start_time": "2019-11-24T05:00:51.418Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train model with 100 speakers, 3 audios per speaker\n",
    "train_folder = '/Users/greenapple/project5/data/raw/LibriSpeech/train-clean-360'\n",
    "X, y = process_audio.audio_to_features(train_folder, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-24T16:58:39.791889Z",
     "start_time": "2019-11-24T05:01:24.365850Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32376 samples, validate on 8094 samples\n",
      "Epoch 1/1\n",
      "32376/32376 [==============================] - 43034s 1s/step - loss: 0.0309 - acc: 0.9953 - val_loss: 0.0841 - val_acc: 0.9849\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18631a3c8>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "siamese_model_2.fit([X[:, 0], X[:, 1]], y, epochs=1, verbose=True, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T23:53:10.945124Z",
     "start_time": "2019-11-23T23:52:49.811224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/greenapple/anaconda3/envs/project4/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /Users/greenapple/anaconda3/envs/project4/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "siamese_model_1 = load_model('/Users/greenapple/project5/models/01_siamese_model.h5') # load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-23T23:53:17.618999Z",
     "start_time": "2019-11-23T23:53:17.381727Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_4 (Sequential)       (None, 4096)         117479232   input_1[0][0]                    \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 4096)         0           sequential_4[1][0]               \n",
      "                                                                 sequential_4[2][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1)            4097        lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 117,483,329\n",
      "Trainable params: 117,483,329\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "siamese_model_1.summary() # model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = siamese_model_1.evaluate(X, y, verbose=0) # evaluate model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:project4] *",
   "language": "python",
   "name": "conda-env-project4-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "280px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
